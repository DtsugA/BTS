{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "171735c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# STEP 0 - Import necessary files and define functions\n",
    "########################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import numpy, math\n",
    "from sklearn.cluster import SpectralClustering, DBSCAN, AgglomerativeClustering\n",
    "import statistics as stats \n",
    "\n",
    "mod = Doc2Vec.load('doc2vecR.200.30.20.5.1550908281.eAp.trained')\n",
    "\n",
    "# Cosine similarity: 1=identical, 0=completely different\n",
    "def cos_sim (av, bv):\n",
    "    return (sum(av*bv)/math.sqrt(sum(av*av)*sum(bv*bv)))\n",
    "\n",
    "# Distinguish docvecs vectors between projects, developers, and languages\n",
    "def typeCheck(vec):\n",
    "    field = vec[0]\n",
    "    maybeDev = False\n",
    "    isDev = False\n",
    "    isPro = False\n",
    "    isLan = False\n",
    "    for c in field:\n",
    "        if c == '<' and not maybeDev:\n",
    "            maybeDev = True\n",
    "        elif c == '>' and maybeDev:\n",
    "            isDev = True\n",
    "        elif c == '_':\n",
    "            isPro = True\n",
    "    if isDev:\n",
    "        return 'dev'\n",
    "    elif isPro:\n",
    "        return 'pro'\n",
    "    else :\n",
    "        return 'lan'\n",
    "    \n",
    "def print_clusters(cluster, names):\n",
    "    for i in range(max(cluster)+1):\n",
    "        print('-'*40)\n",
    "        print(\"Group \" + str(i))\n",
    "        for j in range(len(cluster)):\n",
    "            if cluster[j] == i:\n",
    "                print(names[j])\n",
    "\n",
    "def array_clusters(cluster, names):\n",
    "    res = []\n",
    "    for i in range(max(cluster)+1):\n",
    "        res.append([])\n",
    "        for j in range(len(cluster)):\n",
    "            if cluster[j] == i:\n",
    "                temp = names[j]\n",
    "                res[-1].append(temp)\n",
    "    return res\n",
    "\n",
    "# Import questions into dataframe\n",
    "dTypes = {'Language': object, 'Library': object, 'Unnamed: 0': object, 'Id': object, 'PostTypeId': object, 'AcceptedAnswerId': object, 'CreationDate': object, 'Score': object, 'ViewCount': object, 'Body': object, 'LastEditDate': object, 'LastActivityDate': object, 'Title': object, 'Tags': object, 'AnswerCount': object, 'ClosedDate': object}\n",
    "dateCols = ['CreationDate', 'LastEditDate', 'LastActivityDate', 'ClosedDate']\n",
    "QuestionLibs = pd.read_csv('SO_BDA_Q_Libraries_in_Skill_Space.csv', dtype=dTypes, parse_dates=dateCols)\n",
    "\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs.ViewCount.str.contains(\"-\", na=False)]\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs.PostTypeId.str.contains(\"-\", na=False)]\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs[\"Unnamed: 0\"].str.contains(\"-\", na=False)]\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs[\"Id\"].str.contains(\"-\", na=False)]\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs[\"AcceptedAnswerId\"].str.contains(\"-\", na=False)]\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs[\"Score\"].str.contains(\"-\", na=False)]\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs[\"AnswerCount\"].str.contains(\"-\", na=False)]\n",
    "\n",
    "# Reformat numeric and datetime columns correctly \n",
    "QuestionLibs[\"Unnamed: 0\"] = pd.to_numeric(QuestionLibs[\"Unnamed: 0\"])\n",
    "QuestionLibs[\"Unnamed: 0.1\"] = pd.to_numeric(QuestionLibs[\"Unnamed: 0.1\"])\n",
    "QuestionLibs[\"Id\"] = pd.to_numeric(QuestionLibs[\"Id\"])\n",
    "QuestionLibs[\"PostTypeId\"] = pd.to_numeric(QuestionLibs[\"PostTypeId\"])\n",
    "QuestionLibs[\"AcceptedAnswerId\"] = pd.to_numeric(QuestionLibs[\"AcceptedAnswerId\"])\n",
    "QuestionLibs[\"CreationDate\"] = pd.to_datetime(QuestionLibs[\"CreationDate\"])\n",
    "QuestionLibs[\"Score\"] = pd.to_numeric(QuestionLibs[\"Score\"])\n",
    "QuestionLibs[\"ViewCount\"] = pd.to_numeric(QuestionLibs[\"ViewCount\"])\n",
    "QuestionLibs[\"LastEditDate\"] = pd.to_datetime(QuestionLibs[\"LastEditDate\"])\n",
    "QuestionLibs[\"LastActivityDate\"] = pd.to_datetime(QuestionLibs[\"LastActivityDate\"])\n",
    "QuestionLibs[\"AnswerCount\"] = pd.to_numeric(QuestionLibs[\"AnswerCount\"])\n",
    "QuestionLibs[\"ClosedDate\"] = pd.to_datetime(QuestionLibs[\"ClosedDate\"])\n",
    "\n",
    "QuestionLibs = QuestionLibs[~QuestionLibs[\"CreationDate\"].isna()]\n",
    "\n",
    "# Import answers into dataframe\n",
    "dTypes = {'Language': object, 'Library': object, 'Unnamed: 0': object, 'Id': object, 'PostTypeId': object, 'ParentId': object, 'CreationDate': object, 'Score': object, 'ViewCount': object, 'Body': object, 'LastEditDate': object, 'LastActivityDate': object, 'CommentCount': object}\n",
    "dateCols = ['CreationDate', 'LastEditDate', 'LastActivityDate']\n",
    "AnswerLibs = pd.read_csv('SO_BDA_A_Libraries_in_Skill_Space.csv', dtype=dTypes, parse_dates=dateCols)\n",
    "\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs.ViewCount.str.contains(\"-\", na=False)]\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs.PostTypeId.str.contains(\"-\", na=False)]\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs[\"Unnamed: 0\"].str.contains(\"-\", na=False)]\n",
    "# AnswerLibs = AnswerLibs[~AnswerLibs[\"Unnamed: 0.1\"].str.contains(\"-\", na=False)]\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs[\"Id\"].str.contains(\"-\", na=False)]\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs[\"ParentId\"].str.contains(\"-\", na=False)]\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs[\"Score\"].str.contains(\"-\", na=False)]\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs[\"CommentCount\"].str.contains(\"-\", na=False)]\n",
    "\n",
    "AnswerLibs = AnswerLibs[~AnswerLibs[\"CreationDate\"].isna()]\n",
    "\n",
    "# Reformat numeric and datetime columns correctly \n",
    "AnswerLibs[\"Unnamed: 0\"] = pd.to_numeric(AnswerLibs[\"Unnamed: 0\"])\n",
    "AnswerLibs[\"Unnamed: 0.1\"] = pd.to_numeric(AnswerLibs[\"Unnamed: 0.1\"])\n",
    "AnswerLibs[\"Id\"] = pd.to_numeric(AnswerLibs[\"Id\"])\n",
    "AnswerLibs[\"PostTypeId\"] = pd.to_numeric(AnswerLibs[\"PostTypeId\"])\n",
    "AnswerLibs[\"ParentId\"] = pd.to_numeric(AnswerLibs[\"ParentId\"])\n",
    "AnswerLibs[\"CreationDate\"] = pd.to_datetime(AnswerLibs[\"CreationDate\"])\n",
    "AnswerLibs[\"Score\"] = pd.to_numeric(AnswerLibs[\"Score\"])\n",
    "AnswerLibs[\"ViewCount\"] = pd.to_numeric(AnswerLibs[\"ViewCount\"])\n",
    "AnswerLibs[\"LastEditDate\"] = pd.to_datetime(AnswerLibs[\"LastEditDate\"])\n",
    "AnswerLibs[\"LastActivityDate\"] = pd.to_datetime(AnswerLibs[\"LastActivityDate\"])\n",
    "AnswerLibs[\"CommentCount\"] = pd.to_numeric(AnswerLibs[\"CommentCount\"])\n",
    "\n",
    "QuestionLibs[\"AnswerCount\"] = QuestionLibs[\"AnswerCount\"].replace(0.0, np.nan)\n",
    "AnswerLibs[\"CommentCount\"] = AnswerLibs[\"CommentCount\"].replace(0.0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9c96aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# STEP 2 - Form similarity matrix of libraries that \n",
    "#          appear > 20 times in both Q's and A's\n",
    "########################################################\n",
    "\n",
    "Q_CommonLibs = QuestionLibs.groupby('Language')['Library'].value_counts().loc[lambda x : x>19].rename_axis(['Language','Library']).to_frame('counts')\n",
    "A_CommonLibs = AnswerLibs.groupby('Language')['Library'].value_counts().loc[lambda x : x>19].rename_axis(['Language','Library']).to_frame('counts')\n",
    "QA_CommonLibs = pd.merge(A_CommonLibs, Q_CommonLibs, on=[\"Language\",\"Library\"])\n",
    "QA_CommonLibsList = QA_CommonLibs.index.to_frame(index=False)['Library'].unique().tolist()\n",
    "\n",
    "data = []\n",
    "for lib in QA_CommonLibsList:\n",
    "    row = []\n",
    "    for l in QA_CommonLibsList:\n",
    "        calc = cos_sim(mod.wv.get_vector(lib), mod.wv.get_vector(l))\n",
    "        row.append(calc)\n",
    "    data.append(row)\n",
    "\n",
    "SimMatrix = pd.DataFrame(data, index=QA_CommonLibsList, columns=QA_CommonLibsList)\n",
    "SimMatrixNPArray = SimMatrix.to_numpy()\n",
    "SimMatrixNPMatrix = np.matrix(SimMatrixNPArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c32cf02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py:1593: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  warnings.warn(\"k >= N for N * N square matrix. \"\n",
      "E:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py:507: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n",
      "E:\\ana\\lib\\site-packages\\scipy\\sparse\\linalg\\eigen\\arpack\\arpack.py:1593: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  warnings.warn(\"k >= N for N * N square matrix. \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_samples=10 should be >= n_clusters=11.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_65692/2864822616.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mclustering\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSimMatrixNPMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclustering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    570\u001b[0m             \u001b[0mCluster\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \"\"\"\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# non-optimized default implementation; override when a better\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;31m# method is possible for a given clustering algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         self.labels_ = spectral_clustering(self.affinity_matrix_,\n\u001b[0m\u001b[0;32m    539\u001b[0m                                            \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m                                            \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\cluster\\_spectral.py\u001b[0m in \u001b[0;36mspectral_clustering\u001b[1;34m(affinity, n_clusters, n_components, eigen_solver, random_state, n_init, eigen_tol, assign_labels, verbose)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0massign_labels\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'kmeans'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         _, labels, _ = k_means(maps, n_clusters, random_state=random_state,\n\u001b[0m\u001b[0;32m    281\u001b[0m                                n_init=n_init, verbose=verbose)\n\u001b[0;32m    282\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mReturned\u001b[0m \u001b[0monly\u001b[0m \u001b[1;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_n_iter\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \"\"\"\n\u001b[1;32m--> 289\u001b[1;33m     est = KMeans(\n\u001b[0m\u001b[0;32m    290\u001b[0m         \u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecompute_distances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    982\u001b[0m                                 accept_large_sparse=False)\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ana\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;31m# n_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m             raise ValueError(f\"n_samples={X.shape[0]} should be >= \"\n\u001b[0m\u001b[0;32m    813\u001b[0m                              f\"n_clusters={self.n_clusters}.\")\n\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: n_samples=10 should be >= n_clusters=11."
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# STEP 3 - Perform clustering for different numbers of \n",
    "#          clusters and graph the average std. dev. \n",
    "########################################################\n",
    "\n",
    "res = []\n",
    "sd = []\n",
    "title = []\n",
    "for i in range(1, 50):\n",
    "    clustering = SpectralClustering(i).fit_predict(SimMatrixNPMatrix)\n",
    "    res.append(clustering)\n",
    "\n",
    "\n",
    "k_val_tests = []\n",
    "max_num = 40\n",
    "\n",
    "for m in range(max_num):\n",
    "    # produce a set of clusters\n",
    "    res_array = array_clusters(res[m], QA_CommonLibsList)\n",
    "    clus_av = []\n",
    "\n",
    "    # iterate through each cluster\n",
    "    for j in range(len(res_array)):\n",
    "\n",
    "        clus = res_array[j]\n",
    "        clus_sd = []\n",
    "\n",
    "        # iterate through each element in the cluster being the bench vector\n",
    "        for k in range(len(clus)):\n",
    "            bench = mod.wv.get_vector(clus[k])\n",
    "            temp = []\n",
    "\n",
    "            # calc cos sim of bench vec to all other vectors  \n",
    "            for i in range(len(clus)):\n",
    "                temp.append(cos_sim(bench, mod.wv.get_vector(clus[i])))\n",
    "            try:  \n",
    "                sd = stats.stdev(temp)\n",
    "            except stats.StatisticsError:  \n",
    "                sd = 0.0\n",
    "            clus_sd.append(sd)\n",
    "\n",
    "        try:  \n",
    "            clus_av.append(stats.mean(clus_sd))\n",
    "        except stats.StatisticsError:  \n",
    "            clus_av.append(0.0)\n",
    "    \n",
    "    k_val_tests.append(stats.mean(clus_av))\n",
    "\n",
    "k_index = list(range(1, max_num+1))\n",
    "k_val_tests\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(k_index, k_val_tests, label = \"Line\", marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average SD of nodes in each cluster')\n",
    "plt.title('Maximising cluster numbers')\n",
    "plt.xticks(np.arange(min(k_index), max(k_index)+1, 1.0))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
