{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abc6eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee9d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "      for a in div.find_all(name=\"a\", attrs={\"class\":\"jobtitle\"}):\n",
    "        jobs.append(a[\"title\"])\n",
    "    return(jobs)\n",
    "\n",
    "def extract_company_from_result(soup): \n",
    "  companies = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "    all_company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "    for company in all_company:\n",
    "      companies.append(company.text.strip())    \n",
    "  return(companies)\n",
    "\n",
    "def extract_location_from_result(soup): \n",
    "  locations = []\n",
    "  spans = soup.findAll(\"span\", attrs={\"class\": \"location\"})\n",
    "  for span in spans:\n",
    "    locations.append(span.text)\n",
    "  return(locations)\n",
    "\n",
    "def extract_salary_from_result(soup): \n",
    "  salaries = []\n",
    "  for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "    try:\n",
    "      span = div.find(name=\"span\", attrs={\"class\":\"salaryText\"})\n",
    "      salaries.append(span.text.strip())\n",
    "    except:\n",
    "      salaries.append(\"Nothing_found\")\n",
    "  return(salaries)\n",
    "\n",
    "def extract_summary_from_result(soup): \n",
    "  summaries = []\n",
    "  divs = soup.findAll(\"div\", attrs={\"class\": \"summary\"})\n",
    "  for div in divs:\n",
    "    summaries.append(div.text.strip())\n",
    "  return(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ca937eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 101/101 [01:55<00:00,  1.15s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Job Title, Company Name, Location, Salary, Summary]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing the indexes of the search page url's\n",
    "search_page_list = []\n",
    "for i in range(0,1001,10):\n",
    "  search_page_list.append(i)\n",
    "\n",
    "# defining the lists to store respective data\n",
    "job_title_list = []\n",
    "company_list = []\n",
    "location_list = []\n",
    "salary_list = []\n",
    "summary_list = []\n",
    "\n",
    "# a list of three URL's for three job roles mentioned above.\n",
    "base_URL = [\"https://in.indeed.com/jobs?q=data+scientist&start=\"]\n",
    "\n",
    "for url in base_URL:\n",
    "  for page in tqdm(search_page_list):\n",
    "    URL = url + str(page)\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    job_title_list.extend(extract_job_title_from_result(soup))\n",
    "    company_list.extend(extract_company_from_result(soup))\n",
    "    location_list.extend(extract_location_from_result(soup))\n",
    "    salary_list.extend(extract_salary_from_result(soup))\n",
    "    summary_list.extend(extract_summary_from_result(soup))\n",
    "  \n",
    "\n",
    "column_list = [\"Job Title\", \"Company Name\", \"Location\", \"Salary\", \"Summary\"]\n",
    "\n",
    "data = pd.DataFrame(list(zip(job_title_list, company_list, location_list, salary_list, summary_list)), columns =column_list)\n",
    "\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
