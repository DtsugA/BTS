{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "730de8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# STEP 1 - Merge all .csv files downloaded from Stack \n",
    "#          exchange data explorer\n",
    "########################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "csv_file_list = [\"QueryResults.csv\"]\n",
    "\n",
    "list_of_dataframes = []\n",
    "for filename in csv_file_list:\n",
    "    list_of_dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "merged_df = pd.concat(list_of_dataframes)\n",
    "merged_df.to_csv('StackOverflowBDAQuestions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e606da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# STEP 2 - Split central dataframe into seperate ones \n",
    "#          for questions and answers \n",
    "########################################################\n",
    "\n",
    "df = pd.read_csv('StackOverflowBDAQuestions.csv')\n",
    "\n",
    "questionsDF = df[['Id', 'PostTypeId', 'AcceptedAnswerId', 'CreationDate', 'Score', 'ViewCount', 'Body', 'LastEditDate', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'ClosedDate']].copy()\n",
    "questionsDF = questionsDF.drop_duplicates()\n",
    "\n",
    "answersDF = df[['Id.1', 'PostTypeId.1', 'ParentId', 'CreationDate.1', 'Score.1', 'ViewCount', 'Body.1', 'LastEditDate.1', 'LastActivityDate.1', 'CommentCount']].copy()\n",
    "answersDF.columns = ['Id', 'PostTypeId', 'ParentId', 'CreationDate', 'Score', 'ViewCount', 'Body', 'LastEditDate', 'LastActivityDate', 'CommentCount']\n",
    "\n",
    "questionsDF.to_csv('StackOverflowBDAQuestions_Questions.csv')\n",
    "answersDF.to_csv('StackOverflowBDAQuestions_Answers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b886dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# STEP 3 - Tally import lines for questions and answers\n",
    "########################################################\n",
    "\n",
    "def appendLibrary(lan, lib, row):\n",
    "    templist = [lan] + [lib] + questionsDF.iloc[row].values.tolist()\n",
    "    LibraryDF.loc[len(LibraryDF)] = templist\n",
    "\n",
    "\n",
    "\n",
    "filename = [\n",
    "    'StackOverflowBDAQuestions_Questions.csv',\n",
    "    'StackOverflowBDAQuestions_Answers.csv'\n",
    "]\n",
    "\n",
    "columnNames = [\n",
    "    ['Language', 'Library', 'Unnamed: 0', 'Id', 'PostTypeId', 'AcceptedAnswerId', 'CreationDate', 'Score', 'ViewCount', 'Body', 'LastEditDate', 'LastActivityDate', 'Title', 'Tags', 'AnswerCount', 'ClosedDate'],\n",
    "    ['Language', 'Library', 'Unnamed: 0', 'Id', 'PostTypeId', 'ParentId', 'CreationDate', 'Score', 'ViewCount', 'Body', 'LastEditDate', 'LastActivityDate', 'CommentCount']\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    # Import questions into dataframe\n",
    "    questionsDF = pd.read_csv(filename[i])\n",
    "\n",
    "    # Create dataframe\n",
    "    LibraryDF = pd.DataFrame(columns=columnNames[i])\n",
    "\n",
    "\n",
    "\n",
    "    # C/C++\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "        pattern = \"#include &lt;(.*?)&gt;\"\n",
    "\n",
    "        for m in re.finditer(pattern, text):\n",
    "            appendLibrary(\"C/C++\", m.group(1), index)\n",
    "\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "        pattern = '#include \"(.*?)\"'\n",
    "\n",
    "        for m in re.finditer(pattern, text):\n",
    "            appendLibrary(\"C/C++\", m.group(1), index)\n",
    "\n",
    "\n",
    "\n",
    "    # Java    -     import library;\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "        pattern = \"import (.*?);\"\n",
    "\n",
    "        for m in re.finditer(pattern, text):\n",
    "            text = m.group(1)\n",
    "            \n",
    "            # Clean java mistakes\n",
    "            if ' ' in str(text):\n",
    "                if ' from ' in str(text):\n",
    "                    pattern = \"(?<=from ).*\"\n",
    "                    for m in re.finditer(pattern, text):\n",
    "                        text = m.group()\n",
    "\n",
    "            if ((text[0]=='\"') and (text[-1]=='\"')) or ((text[0]==\"'\") and (text[-1]==\"'\")):\n",
    "                text = text[1:-1]\n",
    "\n",
    "            if '&quot' in text:                     # ending in &quot\n",
    "                pattern = '(?:(?!&quot).)*'\n",
    "                for m in re.finditer(pattern, text):\n",
    "                        text = m.group()\n",
    "                        break\n",
    "\n",
    "            if ' ' in text:                         # keep after \"static \"\n",
    "                pattern = \"(?<=static ).*\"\n",
    "                for m in re.finditer(pattern, text):\n",
    "                    text = m.group()\n",
    "\n",
    "            if ' ' in text:                         # up to first ' '\n",
    "                pattern = '([^\\s]+)'\n",
    "                for m in re.finditer(pattern, text):\n",
    "                    text = m.group()\n",
    "                    break\n",
    "            \n",
    "            appendLibrary(\"Java\", text, index)\n",
    "\n",
    "\n",
    "\n",
    "    # Python    -     import library   or   from library import specific    or    import library as pseudo\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "\n",
    "        pattern = \"import (.*?)\\n\"\n",
    "        for m in re.finditer(pattern, text):\n",
    "            if (';' not in m.group(1)) and \\\n",
    "            ('*' not in m.group(1)) and \\\n",
    "            ('<' not in m.group(1)) and \\\n",
    "            ('>' not in m.group(1)) and \\\n",
    "            ('{' not in m.group(1)) and \\\n",
    "            ('}' not in m.group(1)) and \\\n",
    "            ('(' not in m.group(1)) and \\\n",
    "            (')' not in m.group(1)):\n",
    "                result = m.group(1).split(' ', 1)[0]\n",
    "                result = result.split(',', 1)[0]\n",
    "                result = result.split('.', 1)[0]\n",
    "                appendLibrary(\"Python\", result, index)\n",
    "\n",
    "        pattern = \"import (.*?) \"\n",
    "        for m in re.finditer(pattern, text):\n",
    "            if (';' not in m.group(1)) and \\\n",
    "            ('*' not in m.group(1)) and \\\n",
    "            ('<' not in m.group(1)) and \\\n",
    "            ('>' not in m.group(1)) and \\\n",
    "            ('{' not in m.group(1)) and \\\n",
    "            ('}' not in m.group(1)) and \\\n",
    "            ('(' not in m.group(1)) and \\\n",
    "            (')' not in m.group(1)):\n",
    "                result = m.group(1).split(' ', 1)[0]\n",
    "                result = result.split(',', 1)[0]\n",
    "                result = result.split('.', 1)[0]\n",
    "                appendLibrary(\"Python\", result, index)\n",
    "\n",
    "        pattern = \"from (.*?) import\"\n",
    "        for m in re.finditer(pattern, text):\n",
    "            if (';' not in m.group(1)) and \\\n",
    "            ('*' not in m.group(1)) and \\\n",
    "            ('<' not in m.group(1)) and \\\n",
    "            ('>' not in m.group(1)) and \\\n",
    "            ('{' not in m.group(1)) and \\\n",
    "            ('}' not in m.group(1)) and \\\n",
    "            ('(' not in m.group(1)) and \\\n",
    "            (')' not in m.group(1)):\n",
    "                result = m.group(1).split(' ', 1)[0]\n",
    "                result = result.split(',', 1)[0]\n",
    "                result = result.split('.', 1)[0]\n",
    "                appendLibrary(\"Python\", result, index)\n",
    "\n",
    "\n",
    "\n",
    "    # Javascript    -     <script src=\"libraryURL\">\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "        pattern = \"&lt;script src=&quot;(.*?)&quot;&gt;\"\n",
    "\n",
    "        for m in re.finditer(pattern, text):\n",
    "            text = m.group(1)\n",
    "            if \"@\" in text:\n",
    "                text = text.split('@', 1)[1]\n",
    "            if \"gstatic.com/\" in text:\n",
    "                text = text.split('.com/', 1)[1]\n",
    "            if (text[0] != '/') and ('https' not in text):\n",
    "                text = text.split('/', 1)[0]\n",
    "            if 'firebase' in text:\n",
    "                text = 'firebase'\n",
    "            if 'materialize.min.js' in text:\n",
    "                text = 'materialize'\n",
    "            if 'http' in text:\n",
    "                text = text.split('/')[-1]\n",
    "            if ('.js' in text) or ('&quot;' in text):\n",
    "                continue\n",
    "\n",
    "            appendLibrary(\"JavaScript\", text, index)\n",
    "\n",
    "\n",
    "\n",
    "    # R    -     library(library)\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "        pattern = \"library\\((.*?)\\)\"\n",
    "\n",
    "        for m in re.finditer(pattern, text):\n",
    "            text = m.group(1)\n",
    "\n",
    "            if text:\n",
    "                if text[0] != ' ':\n",
    "                    if ' ' in text:\n",
    "                        text = text.split(' ', 1)[0]\n",
    "                else:\n",
    "                    text = text[1:]\n",
    "                    if ' ' in text:\n",
    "                        text = text.split(' ', 1)[0]\n",
    "\n",
    "                if '&quot;' in text:\n",
    "                    text = text.split('&quot;', 2)[1]\n",
    "\n",
    "                if (text[0] == \"'\") or (text[0] == '\"'):\n",
    "                    text = text[1:-1]\n",
    "\n",
    "                appendLibrary(\"R\", text, index)\n",
    "\n",
    "\n",
    "\n",
    "    # Ruby        rb              require 'library'\n",
    "    for index, element in questionsDF.iterrows():\n",
    "        text = element['Body']\n",
    "        pattern = \"require '(.*?)'\"\n",
    "\n",
    "        for m in re.finditer(pattern, text):\n",
    "            text = m.group(1)\n",
    "            if text:    \n",
    "                if (text[0] == '.') and (text[1] == '/'):\n",
    "                    text = text[2:]\n",
    "                if ' ' in text:\n",
    "                    text = text.split(' ', 1)[0]\n",
    "                if '/' in text:\n",
    "                    text = text.split('/', 1)[0]\n",
    "\n",
    "                appendLibrary(\"Ruby\", text, index)\n",
    "\n",
    "        text = element['Body']\n",
    "        pattern = 'require \"(.*?)\"'\n",
    "        for m in re.finditer(pattern, text):\n",
    "            text = m.group(1)\n",
    "            if text:\n",
    "                if (len(text) > 25):\n",
    "                    continue\n",
    "                if ' ' in text:\n",
    "                    text = text.split(' ', 1)[0]\n",
    "                if '/' in text:\n",
    "                    text = text.split('/', 1)[0]\n",
    "\n",
    "                appendLibrary(\"Ruby\", text, index)\n",
    "\n",
    "\n",
    "\n",
    "    LibraryDF = LibraryDF[LibraryDF.Library != \"&quot\"]\n",
    "    LibraryDF = LibraryDF[LibraryDF.Library != \"\"]\n",
    "    \n",
    "    \n",
    "    mod = Doc2Vec.load ('doc2vecR.200.30.20.5.1550908281.eAp.trained')\n",
    "\n",
    "                \n",
    "    # Reformat numeric and datetime columns correctly \n",
    "    if i==0:\n",
    "        LibraryDF[\"Unnamed: 0\"] = pd.to_numeric(LibraryDF[\"Unnamed: 0\"])\n",
    "        LibraryDF[\"Id\"] = pd.to_numeric(LibraryDF[\"Id\"])\n",
    "        LibraryDF[\"PostTypeId\"] = pd.to_numeric(LibraryDF[\"PostTypeId\"])\n",
    "        LibraryDF[\"AcceptedAnswerId\"] = pd.to_numeric(LibraryDF[\"AcceptedAnswerId\"])\n",
    "        LibraryDF[\"CreationDate\"] = pd.to_datetime(LibraryDF[\"CreationDate\"])\n",
    "        LibraryDF[\"Score\"] = pd.to_numeric(LibraryDF[\"Score\"])\n",
    "        LibraryDF[\"ViewCount\"] = pd.to_numeric(LibraryDF[\"ViewCount\"])\n",
    "        LibraryDF[\"LastEditDate\"] = pd.to_datetime(LibraryDF[\"LastEditDate\"])\n",
    "        LibraryDF[\"LastActivityDate\"] = pd.to_datetime(LibraryDF[\"LastActivityDate\"])\n",
    "        LibraryDF[\"AnswerCount\"] = pd.to_numeric(LibraryDF[\"AnswerCount\"])\n",
    "        LibraryDF[\"ClosedDate\"] = pd.to_datetime(LibraryDF[\"ClosedDate\"])\n",
    "        \n",
    "        LibraryDF.to_csv('SO_BDA_Q_Libraries.csv')\n",
    "        \n",
    "        # Remove all rows that have libraries not in the Skill Space \n",
    "        LibraryDF = LibraryDF[LibraryDF['Library'].isin(mod.wv.vocab)]\n",
    "\n",
    "        LibraryDF.to_csv('SO_BDA_Q_Libraries_in_Skill_Space.csv')\n",
    "\n",
    "    else:\n",
    "        LibraryDF[\"Unnamed: 0\"] = pd.to_numeric(LibraryDF[\"Unnamed: 0\"])\n",
    "        LibraryDF[\"Id\"] = pd.to_numeric(LibraryDF[\"Id\"])\n",
    "        LibraryDF[\"PostTypeId\"] = pd.to_numeric(LibraryDF[\"PostTypeId\"])\n",
    "        LibraryDF[\"ParentId\"] = pd.to_numeric(LibraryDF[\"ParentId\"])\n",
    "        LibraryDF[\"CreationDate\"] = pd.to_datetime(LibraryDF[\"CreationDate\"])\n",
    "        LibraryDF[\"Score\"] = pd.to_numeric(LibraryDF[\"Score\"])\n",
    "        LibraryDF[\"ViewCount\"] = pd.to_numeric(LibraryDF[\"ViewCount\"])\n",
    "        LibraryDF[\"LastEditDate\"] = pd.to_datetime(LibraryDF[\"LastEditDate\"])\n",
    "        LibraryDF[\"LastActivityDate\"] = pd.to_datetime(LibraryDF[\"LastActivityDate\"])\n",
    "        LibraryDF[\"CommentCount\"] = pd.to_numeric(LibraryDF[\"CommentCount\"])\n",
    "\n",
    "        LibraryDF.to_csv('SO_BDA_A_Libraries.csv')\n",
    "        \n",
    "        # Remove all rows that have libraries not in the Skill Space \n",
    "        LibraryDF = LibraryDF[LibraryDF['Library'].isin(mod.wv.vocab)]        \n",
    "        \n",
    "        LibraryDF.to_csv('SO_BDA_A_Libraries_in_Skill_Space.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
